{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_YHgnGtY9-j"
      },
      "outputs": [],
      "source": [
        "# Mostly from https://github.com/kingoflolz/mesh-transformer-jax\n",
        "# So probably under Apache License 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMwYeLI_6tmq"
      },
      "outputs": [],
      "source": [
        "# warning: takes long consider copy to and from drive after first download\n",
        "!time wget -c https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m1XhW0dOnJL"
      },
      "outputs": [],
      "source": [
        "# Copy to drive to not have to do the above again\n",
        "# from google.colab import drive\n",
        "# !cp /content/step_383500_slim.tar.zstd /content/drive/MyDrive/step_383500_slim.tar.zstd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPXJ7WomOuf2"
      },
      "outputs": [],
      "source": [
        "# load from drive \n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')\n",
        "# !cp /content/drive/MyDrive/step_383500_slim.tar.zstd  /content/step_383500_slim.tar.zstd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jA1Pqom6xxg"
      },
      "outputs": [],
      "source": [
        "!apt install zstd\n",
        "!time tar -I zstd -xf step_383500_slim.tar.zstd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9FnK64FyZQk"
      },
      "outputs": [],
      "source": [
        "!pip install numpy tqdm requests optax==0.0.9 dm-haiku==0.0.9 chex==0.1.5 jax==0.3.25 jaxlib==0.3.25 transformers progressbar2 git+https://github.com/Zurnaz/mesh-transformer-jax.git@tpu_driver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EBDzNAaVYDO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests \n",
        "from jax.config import config\n",
        "\n",
        "driver_version=\"tpu_driver_nightly\"\n",
        "# driver_version=\"tpu_driver_20221011\"\n",
        "#  driver_version=\"tpu_driver0.2\"\n",
        "if os.environ.get('COLAB_TPU_ADDR', '') != '':\n",
        "    tpu_address = os.environ['COLAB_TPU_ADDR']  # Colab\n",
        "else:\n",
        "    tpu_address = os.environ['TPU_NAME']  # Kaggle\n",
        "\n",
        "tpu_address = tpu_address.replace(\"grpc://\", \"\")\n",
        "tpu_address_without_port = tpu_address.split(':', 1)[0]\n",
        "url = f'http://{tpu_address_without_port}:8475/requestversion/{driver_version}'\n",
        "requests.post(url)\n",
        "\n",
        "\n",
        "# The following is required to use TPU Driver as JAX's backend.\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + tpu_address\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ro8faMarrA6I"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj9JaWjWyULN"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import jax\n",
        "from jax.experimental import maps\n",
        "import numpy as np\n",
        "import optax\n",
        "import transformers\n",
        "\n",
        "from mesh_transformer.checkpoint import read_ckpt_lowmem, read_ckpt\n",
        "from mesh_transformer.sampling import nucleaus_sample\n",
        "from mesh_transformer.transformer_shard import CausalTransformer, CausalTransformerV2\n",
        "\n",
        "params = {\n",
        "  \"layers\": 28,\n",
        "  \"d_model\": 4096,\n",
        "  \"n_heads\": 16,\n",
        "  \"n_vocab\": 50400,\n",
        "  \"norm\": \"layernorm\",\n",
        "  \"pe\": \"rotary\",\n",
        "  \"pe_rotary_dims\": 64,\n",
        "  \"d_head\": 256,\n",
        "  \"seq\": 2048,\n",
        "  \"cores_per_replica\": 8,\n",
        "  \"per_replica_batch\": 1,\n",
        "}\n",
        "\n",
        "per_replica_batch = params[\"per_replica_batch\"]\n",
        "cores_per_replica = params[\"cores_per_replica\"]\n",
        "seq = params[\"seq\"]\n",
        "\n",
        "\n",
        "params[\"sampler\"] = nucleaus_sample\n",
        "\n",
        "# here we \"remove\" the optimizer parameters from the model (as we don't need them for inference)\n",
        "params[\"optimizer\"] = optax.scale(0)\n",
        "\n",
        "mesh_shape = ( jax.device_count() // cores_per_replica, cores_per_replica)\n",
        "print(\"mesh_shape\", mesh_shape)\n",
        "devices = np.array(jax.devices()).reshape(mesh_shape)\n",
        "print(\"devices\", devices)\n",
        "# maps.thread_resources.env = maps.ResourceEnv(maps.Mesh(devices, ('dp','mp')),())\n",
        "global_mesh = maps.Mesh(devices, ('dp', 'mp'))\n",
        "maps.thread_resources.env = maps.ResourceEnv(physical_mesh=global_mesh, loops=())\n",
        "\n",
        "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "total_batch = per_replica_batch * jax.device_count() // cores_per_replica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mv_ewWme2fEw"
      },
      "outputs": [],
      "source": [
        "network = CausalTransformer(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbpszoqONZzx"
      },
      "outputs": [],
      "source": [
        "# network.state = read_ckpt_lowmem(network.state, \"step_383500/\", devices.shape[1])\n",
        "network.state = read_ckpt(network.state, \"step_383500/\", 8, shards_out=cores_per_replica)\n",
        "network.state = network.move_xmap(network.state, np.zeros(cores_per_replica))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ikzz4b9P2i6R"
      },
      "outputs": [],
      "source": [
        "def infer(context, top_p=0.9, temp=1.0, gen_len=512):\n",
        "    tokens = tokenizer.encode(context)\n",
        "\n",
        "    provided_ctx = len(tokens)\n",
        "    pad_amount = seq - provided_ctx\n",
        "\n",
        "    padded_tokens = np.pad(tokens, ((pad_amount, 0),)).astype(np.uint32)\n",
        "    batched_tokens = np.array([padded_tokens] * total_batch)\n",
        "    length = np.ones(total_batch, dtype=np.uint32) * len(tokens)\n",
        "\n",
        "    start = time.time()\n",
        "    output = network.generate(batched_tokens, length, gen_len, {\"top_p\": np.ones(total_batch) * top_p, \"temp\": np.ones(total_batch) * temp})\n",
        "\n",
        "    samples = []\n",
        "    decoded_tokens = output[1][0]\n",
        "    # print(\"output\", len(output[0]))\n",
        "    for o in decoded_tokens[:, :, 0]:\n",
        "      print(\"o\", len(o))\n",
        "      samples.append(tokenizer.decode(o))\n",
        "\n",
        "      #samples.append(f\"\\033[1m{context}\\033[0m{tokenizer.decode(o)}\")\n",
        "        # single = o[0][0, 0, seq : seq + gen_len]\n",
        "        # print(\"single\", single, tokenizer.decode(single))\n",
        "    print(f\"completion done in {time.time() - start:06}s\")\n",
        "    return samples\n",
        "\n",
        "print(infer(\"EleutherAI is\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l82_b0tC2l4d"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"300px\" }\n",
        "top_p = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "temp = 1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "#context = \"\"\"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\"\"\"\n",
        "context = \"\"\"Google colab is\"\"\"\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=512, context=context))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
